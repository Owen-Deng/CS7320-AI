{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LNvTk3C9_v-"
      },
      "source": [
        "# Adversarial Search: Playing Connect 4\n",
        "\n",
        "Student Name: Chuanqi Deng\n",
        "\n",
        "I have used the following AI tools: ChatGPT\n",
        "\n",
        "I understand that my submission needs to be my own work: CD\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undegraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play Connect 4:\n",
        "\n",
        "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
        "\n",
        "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
        "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqiaBVq79_wA"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model (result function)\n",
        "* Goal state (terminal state and utility)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Initial state:  Empty 6*7 board\n",
        "* Actions: Drop a disc into a column which is not full.\n",
        "* Transition model (result function):  s' = result(a, s). When a player drops a disc into a column, it falls to the lowest available position in that column. If the column is full, the player cannot drop a disc into it, and they must choose a different column.\n",
        "* Goal state (terminal state and utility): A player's 4 discs formed a horizontal, vertical, or diagonal line. A win has a utility of 1, a loss has a utility of -1, and a draw has a utility of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVEQicQq9_wB"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each cell on the game board, there are 3 possibilities: empty, filled with a disc from Player 1, or filled with a disc from Player 2.\\\n",
        "So, for each column, there are 3^6 possible combinations (including the possibility of all cells being empty).\\\n",
        "Since there are 7 columns, we multiply 3^6 by itself 7 times to get the total number of possible game states.\\\n",
        "Therefore, the state space is 3^(6*7) = 3^42."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0oOJCl_9_wB"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the first level of the tree (initial state), there are 7 possible moves.\\\n",
        "At the second level, assuming all columns are available, there are 6 possible moves for the opponent (one less because the column chosen by the first player is now unavailable).\\\n",
        "At the third level, there are again 7 possible moves for the first player.\\\n",
        "This pattern continues, alternating between 7 and 6 possible moves at each level until the game ends or reaches a terminal state.\\\n",
        "The average branching factor can be estimated as the average of 7 and 6, which is approximately 6.5.\\\n",
        "\n",
        "The maximum number of moves until the game ends is 42 (6 rows x 7 columns).\n",
        "Using the average branching factor and the depth of 42 moves, we can estimate the size of the game tree as approximately 6.5^42.\n",
        "Minimax search traverses the complete game tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G21Ssm4Z9_wC"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [25 point]\n",
        "\n",
        "Use a numpy character array as the board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "FUnq0R159_wC",
        "outputId": "d8a26c20-97cf-4a53-b8e7-87cc6db4f567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def empty_board(shape=(6, 7)):\n",
        "    return np.full(shape=shape, fill_value=0, dtype=np.int8)\n",
        "\n",
        "print(empty_board())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3RC3Omw9_wD"
      },
      "source": [
        "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "uKpohDus9_wD",
        "outputId": "012e56ca-ac25-4e87-93fc-c9f8c5782984",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualization code by Randolph Rankin\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize(board):\n",
        "    plt.axes()\n",
        "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
        "    circles=[]\n",
        "    for i,row in enumerate(board):\n",
        "        for j,val in enumerate(row):\n",
        "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
        "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
        "\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    for circle in circles:\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n",
        "board = [[0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 1, -1, 1, 0, 0, 0],\n",
        "         [0, 1, 1, -1, 0, 0, 0],\n",
        "         [0, 1,-1, 1, -1, 0, 0]]\n",
        "visualize(board)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSof4v5L9_wD",
        "tags": []
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* A check for available actions in each state `actions(s)`.\n",
        "* The transition model `result(s, a)`.\n",
        "* Check for terminal states `terminal(s)`.\n",
        "* The utility function `utility(s)`.\n",
        "\n",
        "Make sure that all these functions work with boards of different sizes (number of columns and rows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "Q110Di8r9_wD"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "from copy import deepcopy\n",
        "def actions(s, player = 1):\n",
        "    \"\"\"return non-full column index \"\"\"\n",
        "    ROW, COL = len(s), len(s[0])\n",
        "    res = []\n",
        "    for col in range(COL):\n",
        "        for row in range(ROW):\n",
        "            if s[row][col] == 0:\n",
        "                res.append(col)\n",
        "                break\n",
        "    return res\n",
        "    \n",
        "    \n",
        "def result(s, player, a):\n",
        "    \"\"\"return state based on given action\"\"\"\n",
        "    s_cpy = deepcopy(s)\n",
        "    NUM_ROW = len(s)\n",
        "    for row in range(NUM_ROW-1, -1, -1):\n",
        "        if s_cpy[row][a] == 0:\n",
        "            s_cpy[row][a] = player\n",
        "            break\n",
        "            \n",
        "    return s_cpy\n",
        "\n",
        "def check_win(board):\n",
        "    \"\"\"check the board and return one of 1, -1, d (draw), or n (for next move)\"\"\"\n",
        "    \n",
        "    ROW, COL = len(board), len(board[0])\n",
        "    \n",
        "    # columns \n",
        "    for col in range(COL):\n",
        "        cnt = 1\n",
        "        for row in range(ROW-2, -1, -1):\n",
        "            if board[row][col] == 0: break\n",
        "            if board[row][col] == board[row+1][col]:\n",
        "                cnt += 1\n",
        "            else:\n",
        "                cnt = 1\n",
        "            if cnt == 4:\n",
        "                return board[row][col]\n",
        "    \n",
        "    # rows\n",
        "    for row in range(ROW):\n",
        "        cnt = 1\n",
        "        for col in range(COL-1):\n",
        "            if board[row][col] == board[row][col+1]:\n",
        "                cnt += 1\n",
        "            else:\n",
        "                cnt = 1\n",
        "            if board[row][col] != 0 and cnt == 4:\n",
        "                return board[row][col]\n",
        "    \n",
        "    # diagonals\n",
        "    for start_col in range(3, COL):\n",
        "        if start_col != COL - 1:\n",
        "            start_rows = (ROW - 1,)\n",
        "        else:\n",
        "            start_rows = range(ROW-1, 2, -1)\n",
        "            \n",
        "        for start_row in start_rows:\n",
        "            row, col = start_row - 1, start_col-1\n",
        "            cnt = 1\n",
        "            while row >= 0 and col >= 0:\n",
        "                if board[row][col] == board[row+1][col+1]:\n",
        "                    cnt += 1\n",
        "                else:\n",
        "                    cnt = 1\n",
        "                if board[row][col] != 0 and cnt == 4:\n",
        "                    return board[row][col]\n",
        "                row -= 1\n",
        "                col -= 1\n",
        "                \n",
        "    # diagonals in another direction\n",
        "    for start_col in range(0, COL-4+1):\n",
        "        if start_col != 0:\n",
        "            start_rows = (ROW - 1,)\n",
        "        else:\n",
        "            start_rows = range(ROW-1, 2, -1)\n",
        "            \n",
        "        for start_row in start_rows:\n",
        "            row, col = start_row - 1, start_col + 1\n",
        "            cnt = 1\n",
        "            while row >= 0 and col < COL:\n",
        "                if board[row][col] == board[row+1][col-1]:\n",
        "                    cnt += 1\n",
        "                else:\n",
        "                    cnt = 1\n",
        "                if board[row][col] != 0 and cnt == 4:\n",
        "                    return board[row][col]\n",
        "                row -= 1\n",
        "                col += 1\n",
        "\n",
        "    # check if not in terminal state\n",
        "    for row in range(ROW):\n",
        "        for col in range(COL):\n",
        "            if board[row][col] == 0:\n",
        "                return 'n'\n",
        "            \n",
        "    return 'd'\n",
        "    \n",
        "def terminal(s):\n",
        "    \"\"\"check if s is terminal state\"\"\"\n",
        "    return check_win(s) != 'n'\n",
        "\n",
        "def utility(s, player=1):\n",
        "   \"\"\"check is a state is terminal and return the utility if it is. None means not a terminal mode.\"\"\"\n",
        "   goal = check_win(s)        \n",
        "   if goal == player: return 1\n",
        "   if goal == 'd': return 0  \n",
        "   if goal == -1 * player: return -1  # loss is failure\n",
        "   return None # continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNf_76NU9_wD"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = 1): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "yC84sry79_wD"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "def random_player(board, player = 1):\n",
        "    return np.random.choice(actions(board))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMygwnky9_wD"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "NioCNEXZ9_wD",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 541, -1: 456, 0: 3}"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "def switch_player(player, player1, palyer2):\n",
        "    if player == 1:\n",
        "        return -1, palyer2\n",
        "    else:\n",
        "        return 1, player1\n",
        "\n",
        "def play(player1, palyer2, N = 1000, bord_size = (6, 7)):\n",
        "    \"\"\"Let two agents play each other N times. 1 starts. player1 and palyer2 are agent functions that \n",
        "    get the board as the percept and return their next action.\"\"\"\n",
        "    results = {1: 0, -1: 0, 0: 0}\n",
        "    \n",
        "    for _ in range(N):\n",
        "        board = empty_board(bord_size)\n",
        "        player, fun = 1, player1\n",
        "        \n",
        "        while not terminal(board):\n",
        "            a = fun(board, player)\n",
        "            board = result(board, player, a)\n",
        "            player, fun = switch_player(player, player1, palyer2)   \n",
        "            \n",
        "        win = utility(board)   # returns the 'n' if the game is not done.\n",
        "        results[win] += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "play(random_player, random_player)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AMhgWGA9_wD"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
        "\n",
        "### Implement the Search [20 points]\n",
        "\n",
        "Implement minimax search starting from a given board for specifying the player.\n",
        "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "\n",
        "__Important Notes:__\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
        "This is essential to be able play against agents from other students later.\n",
        "* The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 \\times 4$) and/or changing the winning rule to connect 3 instead of 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "ccnCCWOI9_wD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "# Your code/ answer goes here.\n",
        "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
        "COUNT = 0\n",
        "\n",
        "def alpha_beta_search(board, player = 1):\n",
        "    \"\"\"start the search.\"\"\"\n",
        "    global DEBUG, COUNT\n",
        "    COUNT = 0\n",
        "    \n",
        "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
        "    \n",
        "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
        "    \n",
        "    return { \"move\": move, \"value\": value }\n",
        "\n",
        "def max_value_ab(state, player, alpha, beta):\n",
        "    \"\"\"player's best move.\"\"\"\n",
        "    global DEBUG, COUNT\n",
        "    COUNT += 1\n",
        "       \n",
        "    # return utility of state is a terminal state\n",
        "    v = utility(state, player)\n",
        "    if DEBUG >= 2: print(f\"max: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
        "    if v is not None: \n",
        "        if DEBUG >= 2: print(f\"     found terminal state. backtracking.\")\n",
        "        return v, None\n",
        "        \n",
        "    v, move = -math.inf, None\n",
        "\n",
        "    # check all possible actions in the state, update alpha and return move with the largest value\n",
        "    for a in actions(state):\n",
        "        v2, a2 = min_value_ab(result(state, player, a), player, alpha, beta)\n",
        "        if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
        "        \n",
        "        if v2 > v:\n",
        "            v, move = v2, a\n",
        "            alpha = max(alpha, v)\n",
        "        if v >= beta:\n",
        "            if DEBUG >= 2: print(f\"     v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
        "            return v, move\n",
        "    \n",
        "    return v, move\n",
        "\n",
        "def min_value_ab(state, player, alpha, beta):\n",
        "    \"\"\"opponent's best response.\"\"\"\n",
        "    global DEBUG, COUNT\n",
        "    COUNT += 1\n",
        "    \n",
        "    # return utility of state is a terminal state\n",
        "    v = utility(state, player)\n",
        "    if DEBUG >= 2: print(f\"min: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
        "    if v is not None: \n",
        "        if DEBUG >= 2: print(f\"     found terminal state. backtacking.\")\n",
        "        return v, None\n",
        "    \n",
        "    v, move = +math.inf, None\n",
        "\n",
        "    # check all possible actions in the state, update beta and return move with the smallest value\n",
        "    for a in actions(state):\n",
        "        v2, a2 = max_value_ab(result(state, -1 * player, a), player, alpha, beta)\n",
        "        if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
        "        \n",
        "        if v2 < v:\n",
        "            v, move = v2, a\n",
        "            beta = min(beta, v)\n",
        "        if v <= alpha: \n",
        "            if DEBUG >= 2: print(f\"     v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
        "            return v, move\n",
        "    \n",
        "    return v, move\n",
        "\n",
        "\n",
        "class AlphaBetaAgent:\n",
        "    def __init__(self, name = \"AlphaBetaAgent\"):\n",
        "        self.name = name\n",
        "        self.state = None\n",
        "    \n",
        "    def act(self, board, player):\n",
        "        move = alpha_beta_search(board, player)['move']\n",
        "        self.state = result(board, player, move)\n",
        "        return move\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKFr-sdd9_wE"
      },
      "source": [
        "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "vo-10JDU9_wE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes searched: 8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 0, 'value': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1.51 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched: 27\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 0, 'value': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1.01 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched: 13\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 2, 'value': 0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched: 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 3, 'value': 0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched: 5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 0, 'value': -1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1e+03 Âµs\n"
          ]
        }
      ],
      "source": [
        "board = [[0, 0, 0,-1],\n",
        "         [1,-1,-1, 1],\n",
        "         [1,-1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[0, 0, 0, 0],\n",
        "         [1,-1,-1, 0],\n",
        "         [1,-1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[-1, 0, 0, 0],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1,-1],\n",
        "         [ 1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[-1, 1, 1, 0],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1,-1],\n",
        "         [ 1,-1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[ 0, 1, 0, 1],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [-1, 1,-1,-1]]\n",
        "%time display(alpha_beta_search(board, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmuLQBkl9_wE"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "Z_w0mmdr9_wE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes searched: 3697\n",
            "board 3x4: 0.15 seconds.\n",
            "Number of nodes searched: 62889\n",
            "board 4x4: 3.54 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for size in [(3, 4), (4,4)]:\n",
        "    board = empty_board(size)\n",
        "    start_time = time.time()\n",
        "    alpha_beta_search(board, 1)\n",
        "    used_time = time.time() - start_time\n",
        "    print(f\"board {size[0]}x{size[1]}: {used_time:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8LtIBE89_wE"
      },
      "source": [
        "### Move ordering [5 points]\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I assign each column a priority. The actions will be sorted based on cooresponding priorities. So, the alpha_beta_search will go to columns with higher priority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "AeKcs_lR9_wE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes searched: 62889\n",
            "Number of nodes searched: 62030\n",
            "Number of nodes searched: 59265\n",
            "Number of nodes searched: 58290\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stategy</th>\n",
              "      <th>Time Used(s)</th>\n",
              "      <th>Node Searched</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>3.331542</td>\n",
              "      <td>62889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 0, 1, 1]</td>\n",
              "      <td>3.438386</td>\n",
              "      <td>62030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 0, 1]</td>\n",
              "      <td>3.322894</td>\n",
              "      <td>59265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, 1, 0, 1]</td>\n",
              "      <td>3.306622</td>\n",
              "      <td>58290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Stategy  Time Used(s)  Node Searched\n",
              "0  [0, 0, 0, 0]      3.331542          62889\n",
              "1  [1, 0, 1, 1]      3.438386          62030\n",
              "2  [1, 1, 0, 1]      3.322894          59265\n",
              "3  [0, 1, 0, 1]      3.306622          58290"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "priorities = [[0,0,0,0], [1, 0, 1, 1], [1, 1, 0, 1], [0, 1, 0, 1]]\n",
        "table_data = []\n",
        "for priority in priorities:\n",
        "    def actions(s, player = 1):\n",
        "        \"\"\"return non-full column index with ordering \"\"\"\n",
        "        ROW, COL = len(s), len(s[0])\n",
        "        res = []\n",
        "        \n",
        "        for col in range(COL):\n",
        "            for row in range(ROW):\n",
        "                if s[row][col] == 0:\n",
        "                    res.append((priority[col],col))\n",
        "                    break\n",
        "                \n",
        "        actions = [a for _, a in sorted(res, reverse=True)]\n",
        "        \n",
        "        return actions\n",
        "    start_time = time.time()\n",
        "    alpha_beta_search(board, 1)\n",
        "    used_time = time.time() - start_time\n",
        "    table_data.append([priority, used_time, COUNT])\n",
        "\n",
        "pd.DataFrame(table_data, columns= [\"Stategy\", \"Time Used(s)\", \"Node Searched\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt2N8X-39_wE"
      },
      "source": [
        "### The first few moves [5 points]\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the first few moves, the agent can only explore those actions with higher priority.\n",
        "Or, use a fixed pattern that have higher chance to win the game to place the discs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgf6RC9Z9_wE"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "_FEa4V589_wE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 0, -1: 14, 0: 6}"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def actions(s, player = 1):\n",
        "        \"\"\"return non-full column index with ordering \"\"\"\n",
        "        ROW, COL = len(s), len(s[0])\n",
        "        res = []\n",
        "        priority = [0 if i % 2 == 0 else 1  for i in range(COL)]\n",
        "        for col in range(COL):\n",
        "            for row in range(ROW):\n",
        "                if s[row][col] == 0:\n",
        "                    res.append((priority[col],col))\n",
        "                    break\n",
        "                \n",
        "        actions = [a for _, a in sorted(res, reverse=True)]\n",
        "        \n",
        "        return actions\n",
        "    \n",
        "ab_agent = AlphaBetaAgent()\n",
        "DEBUG = 0\n",
        "play(random_player, ab_agent.act, 20, (4, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to the result, Alpha-Beta Agent wins most of the time and the random agent never wins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg2nPMfE9_wE"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search\n",
        "\n",
        "### Heuristic evaluation function [15 points]\n",
        "\n",
        "Define and implement a heuristic evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "ED6YeQwh9_wE"
      },
      "outputs": [],
      "source": [
        "def is_valid(board, row, col, ROW, COL, check_below_4th):\n",
        "    if row < 0 or row >= ROW or col < 0 or col >= COL\\\n",
        "        or board[row][col] != 0:\n",
        "        return False\n",
        "    if not check_below_4th:\n",
        "        return True\n",
        "    if row == ROW - 1:\n",
        "        return True\n",
        "    if board[row+1][col] == 0:\n",
        "        return False\n",
        "    return True\n",
        "    \n",
        "    \n",
        "def eval_fun(board, player = 1, check_below_4th = True):\n",
        "    \"\"\"heuristic for utility of state. Returns score for a node:\n",
        "    1. For terminal states it returns the utility. \n",
        "    2. For non-terminal states, it calculates a weighted linear function using features of the state. \n",
        "    The features we look at are 3 in a row/col/diagonal where the 4th square is empty. We assume that\n",
        "    the more of these positions we have, the higher the chance of winning.\n",
        "    We need to be careful that the utility of the heuristic stays between [-1,1]. \n",
        "    Note that the largest possible number of these positions is smaller than ROW*COL. I weigh the count by 1/(ROW*COL), \n",
        "    guaranteeing that is in the needed range.\n",
        "    \n",
        "    Function Returns: heuistic value, terminal?\"\"\"\n",
        "    \n",
        "    # terminal state?\n",
        "    u = utility(board, player)\n",
        "    if u is not None: return u, True\n",
        "      \n",
        "    score = 0\n",
        "    ROW, COL = len(board), len(board[0])\n",
        "    score_one = 1/(ROW*COL)\n",
        "    \n",
        "    # columns \n",
        "    for col in range(COL):\n",
        "        cnt = 1\n",
        "        for row in range(ROW-2, -1, -1):\n",
        "            if board[row][col] == 0: break\n",
        "            if board[row][col] == board[row+1][col]:\n",
        "                cnt += 1\n",
        "            else:\n",
        "                cnt = 1\n",
        "            if cnt == 3 and row-1>=0 and board[row-1][col] == 0:\n",
        "                score += board[row][col] * score_one \n",
        "    \n",
        "    # rows\n",
        "    for row in range(ROW):\n",
        "        cnt = 1\n",
        "        for col in range(COL-1):\n",
        "            if board[row][col] == board[row][col+1]:\n",
        "                cnt += 1\n",
        "            else:\n",
        "                cnt = 1\n",
        "            if board[row][col] != 0 and cnt == 3 and \\\n",
        "                (is_valid(board, row, col-2, ROW, COL, check_below_4th) or is_valid(board, row, col+2, ROW, COL, check_below_4th)):\n",
        "                score += board[row][col] * score_one \n",
        "    \n",
        "    # diagonals \\ \n",
        "    for start_col in range(3, COL):\n",
        "        if start_col != COL - 1:\n",
        "            start_rows = (ROW - 1,)\n",
        "        else:\n",
        "            start_rows = range(ROW-1, 2, -1)\n",
        "            \n",
        "        for start_row in start_rows:\n",
        "            row, col = start_row - 1, start_col-1\n",
        "            cnt = 1\n",
        "            while row >= 0 and col >= 0:\n",
        "                if board[row][col] == board[row+1][col+1]:\n",
        "                    cnt += 1\n",
        "                else:\n",
        "                    cnt = 1\n",
        "                if board[row][col] != 0 and cnt == 3 and \\\n",
        "                    (is_valid(board, row+3, col+3, ROW, COL, check_below_4th) or is_valid(board, row-1, col-1, ROW, COL, check_below_4th)):\n",
        "                    score += board[row][col] * score_one \n",
        "                row -= 1\n",
        "                col -= 1\n",
        "                \n",
        "    # diagonals in another direction /\n",
        "    for start_col in range(0, COL-4+1):\n",
        "        if start_col != 0:\n",
        "            start_rows = (ROW - 1,)\n",
        "        else:\n",
        "            start_rows = range(ROW-1, 2, -1)\n",
        "            \n",
        "        for start_row in start_rows:\n",
        "            row, col = start_row - 1, start_col + 1\n",
        "            cnt = 1\n",
        "            while row >= 0 and col < COL:\n",
        "                if board[row][col] == board[row+1][col-1]:\n",
        "                    cnt += 1\n",
        "                else:\n",
        "                    cnt = 1\n",
        "                if board[row][col] != 0 and cnt == 3 and \\\n",
        "                    (is_valid(board, row+3, col-3, ROW, COL, check_below_4th) or is_valid(board, row-1, col+1, ROW, COL, check_below_4th)):\n",
        "                    score += board[row][col] * score_one \n",
        "                row -= 1\n",
        "                col += 1\n",
        "    \n",
        "    return score, False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk0Li5029_wE"
      },
      "source": [
        "### Cutting Off Search [10 points]\n",
        "\n",
        "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "OFxoIqni9_wE"
      },
      "outputs": [],
      "source": [
        "# global variables\n",
        "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
        "COUNT = 0\n",
        "\n",
        "def alpha_beta_search(board, cutoff = None, check_below_4th = True, player = 1):\n",
        "    \"\"\"start the search. cutoff = None is minimax search with alpha-beta pruning.\"\"\"\n",
        "    global DEBUG, COUNT\n",
        "    COUNT = 0\n",
        "\n",
        "    value, move = max_value_ab(board, player, -math.inf, +math.inf, 0, cutoff, check_below_4th)\n",
        "    \n",
        "    if DEBUG >= 1: print(f\"Number of nodes searched (cutoff = {cutoff}): {COUNT}\") \n",
        "    \n",
        "    return {\"move\": move, \"value\": value}\n",
        "\n",
        "def max_value_ab(state, player, alpha, beta, depth, cutoff, check_below_4th = True):\n",
        "    \"\"\"player's best move.\"\"\"\n",
        "    global DEBUG, COUNT\n",
        "    COUNT += 1\n",
        "    \n",
        "    # cut off and terminal test\n",
        "    v, terminal = eval_fun(state, player, check_below_4th)\n",
        "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
        "        if(terminal): \n",
        "            alpha, beta = v, v\n",
        "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
        "        return v, None\n",
        "    \n",
        "    v, move = -math.inf, None\n",
        "\n",
        "    # check all possible actions in the state, update alpha and return move with the largest value\n",
        "    for a in actions(state):\n",
        "        v2, a2 = min_value_ab(result(state, player, a), player, alpha, beta, depth + 1, cutoff, check_below_4th)\n",
        "        if v2 > v:\n",
        "            v, move = v2, a\n",
        "            alpha = max(alpha, v)\n",
        "        if v >= beta: return v, move\n",
        "    \n",
        "    return v, move\n",
        "\n",
        "def min_value_ab(state, player, alpha, beta, depth, cutoff, check_below_4th = True):\n",
        "    \"\"\"opponent's best response.\"\"\"\n",
        "    global DEBUG, COUNT\n",
        "    COUNT += 1\n",
        "    \n",
        "    # cut off and terminal test\n",
        "    v, terminal = eval_fun(state, player, check_below_4th)\n",
        "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
        "        if(terminal): \n",
        "            alpha, beta = v, v\n",
        "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
        "        return v, None\n",
        "    \n",
        "    v, move = +math.inf, None\n",
        "\n",
        "    # check all possible actions in the state, update beta and return move with the smallest value\n",
        "    for a in actions(state):\n",
        "        v2, a2 = max_value_ab(result(state, -1 * player, a), player, alpha, beta, depth + 1, cutoff, check_below_4th)\n",
        "        if v2 < v:\n",
        "            v, move = v2, a\n",
        "            beta = min(beta, v)\n",
        "        if v <= alpha: return v, move\n",
        "    \n",
        "    return v, move\n",
        "\n",
        "class HeuristicAgent:\n",
        "    def __init__(self, cutoff = 8, check_below_4th = True, name = \"HeuristicAgent\"):\n",
        "        self.name = name\n",
        "        self.state = None\n",
        "        self.cutoff = cutoff\n",
        "        self.check_below_4th = check_below_4th\n",
        "    \n",
        "    def act(self, board, player):\n",
        "        move = alpha_beta_search(board, self.cutoff , player)['move']\n",
        "        self.state = result(board, player, move)\n",
        "        return move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes searched (cutoff = 10): 8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 3, 'value': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 2 ms\n",
            "Number of nodes searched (cutoff = 5): 8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 3, 'value': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 2.01 ms\n"
          ]
        }
      ],
      "source": [
        "board = [[0, 0, 0, 0],\n",
        "         [0, 1, 1, 1],\n",
        "         [1, 1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 10, 1))\n",
        "board = [[0, 0, 0, 0],\n",
        "         [0, 1, 1, 1],\n",
        "         [1, 1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 5, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPqW7Drp9_wE"
      },
      "source": [
        "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "9sgpdC-L9_wE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes searched (cutoff = 10): 11\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 0, 'value': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1.05 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched (cutoff = 10): 71\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 0, 'value': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 3.32 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched (cutoff = 10): 14\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 2, 'value': 0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1.51 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched (cutoff = 10): 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 3, 'value': 0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1.01 ms\n",
            "---------------------------------------\n",
            "Number of nodes searched (cutoff = 10): 5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'move': 2, 'value': -1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 1.51 ms\n"
          ]
        }
      ],
      "source": [
        "board = [[0, 0, 0,-1],\n",
        "         [1,-1,-1, 1],\n",
        "         [1,-1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 10, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[0, 0, 0, 0],\n",
        "         [1,-1,-1, 0],\n",
        "         [1,-1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 10, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[-1, 0, 0, 0],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1,-1],\n",
        "         [ 1, 1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 10, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[-1, 1, 1, 0],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1,-1],\n",
        "         [ 1,-1,-1, 1]]\n",
        "%time display(alpha_beta_search(board, 10, 1))\n",
        "print('---------------------------------------')\n",
        "\n",
        "board = [[ 0, 1, 0, 1],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [-1, 1,-1,-1]]\n",
        "%time display(alpha_beta_search(board, 10, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pRc_m29_wE"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "5fZARdf79_wE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes searched (cutoff = 8): 2816\n",
            "board 4x5: 0.43 seconds.\n",
            "Number of nodes searched (cutoff = 8): 8916\n",
            "board 5x6: 1.40 seconds.\n",
            "Number of nodes searched (cutoff = 8): 15369\n",
            "board 6x7: 3.58 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for size in [(4, 5), (5, 6), (6, 7)]:\n",
        "    board = empty_board(size)\n",
        "    start_time = time.time()\n",
        "    alpha_beta_search(board, 8, 1)\n",
        "    used_time = time.time() - start_time\n",
        "    print(f\"board {size[0]}x{size[1]}: {used_time:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D3So-cG9_wE"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "nsA0IjfC9_wE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 1, -1: 0, 0: 0}"
            ]
          },
          "execution_count": 370,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEBUG = 0\n",
        "\n",
        "# differenet evaluation function controlled by the second parameter.\n",
        "heuristic_agent1 = HeuristicAgent(8, True)\n",
        "heuristic_agent2 = HeuristicAgent(2, False)\n",
        "play(heuristic_agent1.act, random_player, 1, (5, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKSuDP7x9_wI"
      },
      "source": [
        "## Challenge task [up to +10 bonus point will be awarded separately]\n",
        "\n",
        "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzXTZv639_wI"
      },
      "source": [
        "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
        "\n",
        "### Pure Monte Carlo Search\n",
        "\n",
        "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "u189giXd9_wI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "-1\n",
            "1\n",
            "-1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "def playout(state, action, player = 1):\n",
        "    \"\"\"Perfrom a random playout starting with the given action on the fiven board \n",
        "    and return the utility of the finished game.\"\"\"\n",
        "    state = result(state, player, action)\n",
        "    current_player = -1 * player\n",
        "    \n",
        "    while(True):\n",
        "        # reached terminal state?\n",
        "        u = utility(state, player)\n",
        "        if u is not None: return(u)\n",
        "        \n",
        "        # we use a random playout policy\n",
        "        a = np.random.choice(actions(state))\n",
        "        state = result(state, current_player, a)\n",
        "        #print(state)\n",
        "        \n",
        "        # switch between players\n",
        "        current_player = -1 * current_player\n",
        "\n",
        "\n",
        "# Playout for action 0 (top-left corner)\n",
        "board = empty_board()\n",
        "print(playout(board, 0))\n",
        "print(playout(board, 0))\n",
        "print(playout(board, 0))\n",
        "print(playout(board, 0))\n",
        "print(playout(board, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Playout results: [-1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1]\n",
            "mean utility: 0.36\n",
            "win probability: 0.68\n",
            "loss probability: 0.32\n",
            "draw probability: 0.0\n"
          ]
        }
      ],
      "source": [
        "def playouts(board, action, player = 1, N = 100):\n",
        "    \"\"\"Perform N playouts following the given action for the given board.\"\"\"\n",
        "    return [ playout(board, action, player) for i in range(N) ]\n",
        "\n",
        "u = playouts(board, 3)\n",
        "print(\"Playout results:\", u)\n",
        "\n",
        "print(f\"mean utility: {np.mean(u)}\")\n",
        "\n",
        "p_win = sum(np.array(u) == +1)/len(u)\n",
        "p_loss = sum(np.array(u) == -1)/len(u)\n",
        "p_draw = sum(np.array(u) == 0)/len(u)\n",
        "print(f\"win probability: {p_win}\")\n",
        "print(f\"loss probability: {p_loss}\")\n",
        "print(f\"draw probability: {p_draw}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions: [5, 3, 1, 6, 4, 2, 0] (100 total playouts = 14 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{5: 0.0,\n",
              " 3: 0.2857142857142857,\n",
              " 1: 0.14285714285714285,\n",
              " 6: 0.14285714285714285,\n",
              " 4: 0.7142857142857143,\n",
              " 2: 0.2857142857142857,\n",
              " 0: 0.14285714285714285}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "CPU times: total: 31.2 ms\n",
            "Wall time: 324 ms\n",
            "\n",
            "10000 playouts give a better utility estimate.\n",
            "Actions: [5, 3, 1, 6, 4, 2, 0] (10000 total playouts = 1428 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{5: 0.12394957983193278,\n",
              " 3: 0.3067226890756303,\n",
              " 1: 0.055322128851540614,\n",
              " 6: 0.03571428571428571,\n",
              " 4: 0.14775910364145659,\n",
              " 2: 0.1211484593837535,\n",
              " 0: -0.0273109243697479}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "CPU times: total: 6.22 s\n",
            "Wall time: 31.2 s\n"
          ]
        }
      ],
      "source": [
        "DEBUG = 1\n",
        "\n",
        "\n",
        "def pmcs(board, N = 100, player = 1):\n",
        "    \"\"\"Pure Monte Carlo Search. Returns the action that has the largest average utility.\n",
        "    The N playouts are evenly divided between the possible actions.\"\"\"\n",
        "    global DEBUG\n",
        "    \n",
        "    acts = actions(board)\n",
        "    n = math.floor(N/len(acts))\n",
        "    if DEBUG >= 1: print(f\"Actions: {acts} ({N} total playouts = {n} playouts per action)\")\n",
        "    \n",
        "    ps = { i : np.mean(playouts(board, i, player, N = n)) for i in acts }\n",
        "    if DEBUG >= 1: display(ps)\n",
        "        \n",
        "    action = max(ps, key=ps.get)\n",
        "    return action\n",
        "\n",
        "board = empty_board()\n",
        "display(board)\n",
        "%time print(pmcs(board))\n",
        "\n",
        "print()\n",
        "print(\"10000 playouts give a better utility estimate.\")\n",
        "%time print(pmcs(board, N = 10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions: [1, 2, 0] (100 total playouts = 33 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: -0.45454545454545453, 2: 0.3939393939393939, 0: 1.0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 7.69 ms\n",
            "--------------------------------------------------------------\n",
            "Actions: [3, 1, 2, 0] (100 total playouts = 25 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{3: -0.24, 1: -0.64, 2: 0.52, 0: 1.0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 9.54 ms\n",
            "--------------------------------------------------------------\n",
            "Actions: [3, 1, 2] (100 total playouts = 33 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{3: -0.48484848484848486, 1: -0.45454545454545453, 2: 0.0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 9.52 ms\n",
            "--------------------------------------------------------------\n",
            "Actions: [3] (100 total playouts = 100 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{3: 0.0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 4 ms\n",
            "--------------------------------------------------------------\n",
            "Actions: [2, 0] (100 total playouts = 50 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{2: -1.0, 0: -1.0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 5.51 ms\n"
          ]
        }
      ],
      "source": [
        "board = [[0, 0, 0,-1],\n",
        "         [1,-1,-1, 1],\n",
        "         [1,-1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(pmcs(board, 100, 1))\n",
        "print('--------------------------------------------------------------')\n",
        "\n",
        "board = [[0, 0, 0, 0],\n",
        "         [1,-1,-1, 0],\n",
        "         [1,-1,-1,-1],\n",
        "         [1, 1,-1, 1]]\n",
        "%time display(pmcs(board, 100, 1))\n",
        "print('--------------------------------------------------------------')\n",
        "\n",
        "board = [[-1, 0, 0, 0],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1,-1],\n",
        "         [ 1, 1,-1, 1]]\n",
        "%time display(pmcs(board, 100, 1))\n",
        "print('--------------------------------------------------------------')\n",
        "\n",
        "board = [[-1, 1, 1, 0],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1,-1],\n",
        "         [ 1,-1,-1, 1]]\n",
        "%time display(pmcs(board, 100, 1))\n",
        "print('--------------------------------------------------------------')\n",
        "\n",
        "board = [[ 0, 1, 0, 1],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [ 1,-1,-1, 1],\n",
        "         [-1, 1,-1,-1]]\n",
        "%time display(pmcs(board, 100, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pz9zg-69_wI"
      },
      "source": [
        "### Best First Move\n",
        "\n",
        "Use Oure Monte Carlo Search to determine what the best first move is? Describe under what assumptions this is the \"best\" first move.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "fuwIJyfh9_wI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions: [5, 3, 1, 6, 4, 2, 0] (5000 total playouts = 714 playouts per action)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{5: 0.07983193277310924,\n",
              " 3: 0.2689075630252101,\n",
              " 1: 0.08403361344537816,\n",
              " 6: 0.0056022408963585435,\n",
              " 4: 0.14145658263305322,\n",
              " 2: 0.17647058823529413,\n",
              " 0: -0.00980392156862745}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 387,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "board = empty_board()\n",
        "pmcs(board, 5000, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the seach above, the best first move is 3. This is in the middle and it makes sense because the player can expand to both left and right. Also, this move makes the other player difficult to defense."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
